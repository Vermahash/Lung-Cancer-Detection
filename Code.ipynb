
import os
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
from tensorflow.keras import layers, models
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.utils.class_weight import compute_class_weight
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score
from sklearn.model_selection import StratifiedKFold
import seaborn as sns
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.applications.resnet50 import preprocess_input

import kagglehub

# Download latest version
path = kagglehub.dataset_download("quynhlecl/lung-cancer-x-ray")
print("Path to dataset files:", path)

# Set the root dataset path
root_dataset_path = "/root/.cache/kagglehub/datasets/quynhlecl/lung-cancer-x-ray/versions/1/chest_xray_lung/"

train_dataset_path = os.path.join(root_dataset_path, "train")
test_dataset_path = os.path.join(root_dataset_path, "test")
val_dataset_path = os.path.join(root_dataset_path, "val")

# Function to explore the dataset
def explore_dataset(dataset_path):
    class_counts = {}
    total_images = 0

    for root, dirs, files in os.walk(dataset_path):
        for folder in dirs:
            folder_path = os.path.join(root, folder)
            num_files = len(os.listdir(folder_path))
            class_counts[folder] = num_files
            total_images += num_files

    print("Dataset Overview:")
    print(f"Total Classes: {len(class_counts)}")
    print(f"Total Images: {total_images}")
    print("Class Distribution:")
    for cls, count in class_counts.items():
        print(f"  {cls}: {count}")

    return class_counts

class_counts = explore_dataset(root_dataset_path)
# Calculate class weights for imbalanced data
class_weights = compute_class_weight(
    'balanced',
    classes=np.unique(list(class_counts.keys())),
    y=np.concatenate([[k] * v for k, v in class_counts.items()])
)
class_weights = dict(enumerate(class_weights))


# Data Augmentation
train_gen = ImageDataGenerator(
    preprocessing_function=preprocess_input,
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True
)

val_test_gen = ImageDataGenerator(preprocessing_function=preprocess_input)

# Data Generators
train_generator = train_gen.flow_from_directory(
    train_dataset_path,
    target_size=(224, 224),
    batch_size=32,
    class_mode='sparse',
    shuffle=True
)
val_generator = val_test_gen.flow_from_directory(
    val_dataset_path,
    target_size=(224, 224),
    batch_size=32,
    class_mode='sparse'
)
test_generator = val_test_gen.flow_from_directory(
    test_dataset_path,
    target_size=(224, 224),
    batch_size=32,
    class_mode='sparse',
    shuffle=False
)
from tensorflow.keras.optimizers import Adam

# Model Definition using ResNet50
def create_model(learning_rate):
    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
    base_model.trainable = False  # Freeze the base model

    model = models.Sequential([
        base_model,
        layers.GlobalAveragePooling2D(),
        layers.Dense(128, activation='relu'),
        layers.Dropout(0.3),
        layers.Dense(train_generator.num_classes, activation='softmax')
    ])
    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='sparse_categorical_crossentropy', metrics=['accuracy'])
    return model

model = create_model(learning_rate=0.001)
model.summary()
from sklearn.model_selection import KFold

# Callbacks for training
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
model_checkpoint = ModelCheckpoint('best_model_resnet.keras', save_best_only=True)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-5)

initial_learning_rate = 0.001

def extract_data_and_labels(generator):
    data = []
    labels = []
    for _ in range(len(generator)):
        images, batch_labels = next(generator)  # Use the built-in next function
        data.append(images)
        labels.append(batch_labels)
    return np.vstack(data), np.concatenate(labels)

# Extract data and labels
train_data, train_labels = extract_data_and_labels(train_generator)

# Initialize KFold
kfold = KFold(n_splits=5, shuffle=True, random_state=42)

# Perform K-Fold Cross-Validation
fold_no = 1
results = []
for train_idx, val_idx in kfold.split(train_data, train_labels):
    print(f"Training Fold {fold_no}...")

    # Create data generators for the current fold
    train_data_gen = ImageDataGenerator(preprocessing_function=preprocess_input).flow(
        train_data[train_idx], train_labels[train_idx], batch_size=16
    )
    val_data_gen = ImageDataGenerator(preprocessing_function=preprocess_input).flow(
        train_data[val_idx], train_labels[val_idx], batch_size=16
    )

    # Create a new model instance
    model = create_model(learning_rate=initial_learning_rate)

    # Train the model
    history = model.fit(
        train_data_gen,
        epochs=10,
        validation_data=val_data_gen,
        callbacks=[early_stopping, model_checkpoint, reduce_lr]
    )

    # Evaluate the model
    val_loss, val_acc = model.evaluate(val_data_gen)
    print(f"Fold {fold_no} - Validation Accuracy: {val_acc:.2f}")
    results.append({'fold': fold_no, 'val_loss': val_loss, 'val_acc': val_acc})
    model.save(f'fold_{fold_no}_model_resnet.keras')


    fold_no += 1
print("\nK-Fold Cross-Validation Results:")
for result in results:
    print(f"Fold {result['fold']} - Loss: {result['val_loss']:.4f}, Accuracy: {result['val_acc']:.4f}")
# Evaluate on the test set
test_loss, test_acc = model.evaluate(test_generator)
print(f"Test Accuracy: {test_acc:.2f}")

# Classification Report and Metrics
y_pred = np.argmax(model.predict(test_generator), axis=1)
y_true = test_generator.classes
print(classification_report(y_true, y_pred, target_names=test_generator.class_indices.keys()))

# AUC-ROC Score
auc = roc_auc_score(y_true, y_pred)
print(f"AUC-ROC: {auc:.2f}")

# Confusion Matrix
cm = confusion_matrix(y_true, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=test_generator.class_indices.keys(),
            yticklabels=test_generator.class_indices.keys())
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

# Visualization of Training Histories
for idx, history in enumerate(histories):
    plt.plot(history.history['accuracy'], label=f'Fold {idx+1} Train Accuracy')
    plt.plot(history.history['val_accuracy'], label=f'Fold {idx+1} Validation Accuracy')

plt.title('Cross-Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()
